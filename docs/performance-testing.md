# Performance testing playbook

This project now includes reproducible Playwright end-to-end scenarios that track
core web-vital metrics (Largest Contentful Paint, Interaction to Next Paint,
Cumulative Layout Shift) as well as Chromium's JS heap usage for high-traffic
flows. Metrics are compared against checked-in budgets so that regressions fail
continuous integration.

## Scenarios under test

The `perf` project in Playwright exercises two heavy user journeys:

- **`desktop-load`** – boots the Kali-inspired desktop, waits for the pinned app
  icons to render, and records vitals on the initial viewport load.
- **`apps-catalog-heavy`** – opens the `/apps` catalogue, filters for the
  Metasploit simulator, and drills into the detail page to mimic a heavier
  security tooling workflow.

Each run attaches raw metrics and a Playwright trace archive to aid debugging.

## Running the checks locally

1. Start the application in another terminal. The perf suite expects a server at
   `http://localhost:3000`:

   ```bash
   yarn dev
   ```

2. Run the performance tests in headless Chromium:

   ```bash
   yarn perf:test
   ```

   The command maps to `npx playwright test --project=perf`, ensuring the new
   suite can be executed in isolation without touching the broader smoke tests.

## Updating baselines intentionally

Budgets live in [`e2e/perf/budgets.json`](../e2e/perf/budgets.json) and the trend
history is tracked in [`e2e/perf/history.json`](../e2e/perf/history.json).
Updates should only happen after a reviewer approves the regression and when the
new values are representative of steady-state performance.

The helper script captures fresh metrics, updates baselines, appends a history
entry, and reminds you to regenerate the dashboard:

```bash
yarn perf:update
```

Before running the command:

- Ensure the production-like server is running (`yarn dev` or `yarn start`).
- Double-check that no other Playwright runs are using the same port.
- Review the git diff for `budgets.json`, `history.json`, and the generated
  dashboard before committing.

Afterwards regenerate the Markdown dashboard:

```bash
yarn perf:report
```

## Dashboard and reporting

The autogenerated [`docs/performance-dashboard.md`](./performance-dashboard.md)
file summarises every recorded run, including budget limits, timestamps, git
references, and memory usage converted to megabytes. Share this document in PRs
when discussing performance changes so reviewers can scan long-term trends.

## Continuous integration

`.github/workflows/ci.yml` now contains a `perf` job that:

1. Installs Playwright browsers in the CI runner.
2. Boots the Next.js dev server in headless mode.
3. Executes `yarn perf:test` so regressions above the configured thresholds fail
   the pipeline.
4. Uploads Playwright traces on failure for debugging.

This keeps the budgets enforceable without requiring manual reviews of build
artifacts. All headless fixtures (viewport, timezone, locale, and cleared
storage) are explicitly configured inside the spec to make runs deterministic.
